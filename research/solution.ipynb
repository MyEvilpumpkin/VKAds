{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Решение"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Подготовка"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Импортируем необходимые для начала работы библиотеки"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Определяем папку, где находятся данные"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "data_dir = os.path.join('..', 'data')"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Загружаем данные"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "users_df = pd.read_csv(os.path.join(data_dir, 'users.tsv'), sep='\\t')\n",
    "history_df = pd.read_csv(os.path.join(data_dir, 'history.tsv'), sep='\\t')\n",
    "validate_df = pd.read_csv(os.path.join(data_dir, 'validate.tsv'), sep='\\t')\n",
    "validate_answers_df = pd.read_csv(os.path.join(data_dir, 'validate_answers.tsv'), sep='\\t')"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "log_transformer = FunctionTransformer(np.log1p)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Работа с \"Историей\""
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Чтобы удобнее было перезапускать частично, периодически будем копировать датафреймы"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "history = history_df.copy()"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "history = history[history['cpm'] < history['cpm'].quantile(0.95)]\n",
    "history = history[history['cpm'] > history['cpm'].quantile(0.05)]\n",
    "history['cpm'] = log_transformer.transform(history['cpm'])"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Проходимся по датафрейму и агрегируем необходимые нам данные"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Можно заменить на вызовы методов датафреймов для необходимых агрегаций, но мне показалось, что так может быть быстрее"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Основные показатели которые нам нужны - набор выигравших cpm для каждого пользователя и распределение пользователей по площадкам "
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "user_cpms = {}\n",
    "publisher_users = {}\n",
    "\n",
    "for index, row in history.iterrows():\n",
    "    user_id = str(int(row['user_id']))\n",
    "    publisher = str(int(row['publisher']))\n",
    "    cpm = row['cpm']\n",
    "\n",
    "    if user_id not in user_cpms:\n",
    "        user_cpms[user_id] = []\n",
    "    user_cpms[user_id].append(cpm)\n",
    "\n",
    "    if publisher not in publisher_users:\n",
    "        publisher_users[publisher] = set()\n",
    "    publisher_users[publisher].add(user_id)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Работа с \"Рекламой\""
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Аналогично копируем датафрейм"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "ads = validate_df.copy()"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "ads['cpm'] = log_transformer.transform(ads['cpm'])"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Создаем фичи  \n",
    "В принципе тут можно без комментариев понять по названиям"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "ads['hours'] = ads.apply(lambda row: row['hour_end'] - row['hour_start'], axis=1)\n",
    "\n",
    "ads['cpm_x_hours'] = ads['cpm'] * ads['hours']"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Далее мы начинаем обходить для каждого рекламного объявления пользователей, которые в нем указаны и создаем фичи на их основе\n",
    "\n",
    "Как показала практика это одни из самых значимых фичей"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "`users_power` - это показатель того, сколько человек смотрит рекламы  \n",
    "не придумал более хорошего названия"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def process_ad_users(user_ids, user_cpms):\n",
    "    users = user_ids.split(',')\n",
    "    counts = []\n",
    "    cpms = []\n",
    "    for user in users:\n",
    "        if user in user_cpms:\n",
    "            counts.append(len(user_cpms[user]))\n",
    "            cpms.append(np.mean(user_cpms[user]))\n",
    "\n",
    "    return sum(counts), np.mean(counts), np.mean(cpms)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "ads[['users_power', 'mean_users_power', 'mean_cpm_per_users']] = ads['user_ids'].apply(\n",
    "    lambda user_ids: process_ad_users(user_ids, user_cpms)\n",
    ").apply(pd.Series)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Здесь примерно то же самое, только обходим по площадкам"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def process_ad_publishers(publisher_ids, publisher_users):\n",
    "    publishers = publisher_ids.split(',')\n",
    "    counts = []\n",
    "    for publisher in publishers:\n",
    "        if publisher in publisher_users:\n",
    "            counts.append(len(publisher_users[publisher]))\n",
    "\n",
    "    return sum(counts), np.mean(counts)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "ads[['active_users_in_publishers', 'mean_active_users_in_publishers']] = ads['publishers'].apply(\n",
    "    lambda publisher_ids: process_ad_publishers(publisher_ids, publisher_users)\n",
    ").apply(pd.Series)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Завершение обработки данных"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Далее будем приводить всё к виду, в котором будет удобно скармливать данные модели"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "features = ads.copy()"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Тут удаляем совсем неподходящие (по типу) колонки"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "features = features.drop(columns=['user_ids', 'publishers'])"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Тут удаляем уже те, которые нам не нравятся (по влиянию на модель)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "features = features.drop(columns=['hour_start', 'hour_end'])"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Вот что у нас получилось по составу колонок"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "features.columns"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Посмотрим на матрицу корреляций"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "corr = features.corr()\n",
    "corr.style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Видно, что некоторые признаки сильно коррелируют, но я не стал их убирать пока, потому что они всё равно полезны для метрики"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "target = validate_answers_df.copy()"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Делим на train и test"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.33, random_state=42)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Работа с моделью"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score \n",
    "\n",
    "def print_metrics(y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "    print(f\"MAE: {mae:.4f}\")\n",
    "    print(f\"MSE: {mse:.4f}\")\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    print(f\"R2: {r2:.4f}\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import optuna\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Используем CatBoostRegressor, потому что модель дает неплохой результат сходу (лучше чем у xgboost и GradientBoostingRegressor)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "from catboost import CatBoostRegressor"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def optimize_catboost(X_train, X_test, y_train, y_test, n_trials=50):\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            \"iterations\": trial.suggest_int(\"iterations\", 100, 1000),\n",
    "            \"depth\": trial.suggest_int(\"depth\", 3, 10),\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.3, log=True),\n",
    "            \"l2_leaf_reg\": trial.suggest_float(\"l2_leaf_reg\", 1e-3, 10.0, log=True),\n",
    "            \"border_count\": trial.suggest_int(\"border_count\", 32, 255),\n",
    "            \"random_strength\": trial.suggest_float(\"random_strength\", 1e-3, 10.0, log=True),\n",
    "            \"bagging_temperature\": trial.suggest_float(\"bagging_temperature\", 0.0, 1.0),\n",
    "            \"loss_function\": \"RMSE\",\n",
    "            \"eval_metric\": \"RMSE\",\n",
    "            \"random_seed\": 42,\n",
    "            \"silent\": True\n",
    "        }\n",
    "\n",
    "        model = CatBoostRegressor(**params)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = model.predict(X_test)\n",
    "        rmse = root_mean_squared_error(y_test, y_pred)\n",
    "        return rmse\n",
    "\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "    return study.best_params, study.best_value"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "X_train1, X_test1, y_train1, y_test1 = features_train, features_test, target_train['at_least_one'], target_test['at_least_one']\n",
    "\n",
    "#params1 = optimize_catboost(X_train1, X_test1, y_train1, y_test1, 200)[0]\n",
    "\n",
    "model1 = CatBoostRegressor(silent=True)\n",
    "model1.fit(X_train1, y_train1)\n",
    "\n",
    "y_true1 = np.array(y_test1)\n",
    "y_pred1 = model1.predict(X_test1)\n",
    "\n",
    "print_metrics(y_true1, y_pred1)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Посмотрим на значимость фичей  \n",
    "Для этого будем использовать библиотеку SHAP"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "import shap"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Инициализируем библиотеку"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "explainer = shap.TreeExplainer(model1)\n",
    "shap_values = explainer(X_train1)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Выведем фичи и их значимость"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "shap.plots.bar(shap_values)"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Также выведем heatmap фич, чтобы увидеть как фичи описывают данные в совокупности (порядок семплов определен библиотекой на основе объясняемой схожести, т.е. библиотка применяет иерархическую кластеризацию для того, чтобы наиболее \"объясняемые\" с помощью наших фич были рядом друг с другом)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "shap.plots.heatmap(shap_values);"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Можно убрать малозначимые и добавить каких-нибудь еще интересных\n",
    "\n",
    "Я пробовал перемножать и делить базовые фичи (cpm, duration, sizes), но там ничего супер полезного не было"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Неплохо  \n",
    "У меня получалось лучше, но там было в 2 раза больше малополезных фичей, а результат не сильно отличался  "
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "График распределения значений"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "result1 = pd.DataFrame()\n",
    "result1['y_test'] = y_test1\n",
    "result1['y_pred'] = y_pred1\n",
    "\n",
    "sns.regplot(data=result1, x='y_test', y='y_pred', scatter_kws={\"s\": 20, \"alpha\": 0.5})\n",
    "\n",
    "x = np.linspace(0, result1.max(), 100)\n",
    "plt.plot(x, x, color=\"red\");"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Видно, что есть некоторая ошибка (расхождение между линиями), но в целом получается неплохо"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Но это пока только один таргет, а нам надо еще 2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Во время анализа данных была выявлена сильная корреляция между таргетами  \n",
    "Воспользуемся этим"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Из всех опробованных моделей (GradientBoostingRegressor, CatBoostRegressor, LinearRegression) без оптимизации гиперпараметров лучше с задачей справляется GradientBoostingRegressor"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "from sklearn.ensemble import GradientBoostingRegressor"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def optimize_gradient_boosting(X_train, X_test, y_train, y_test, n_trials=50):\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 1000),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.3, log=True),\n",
    "            \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "            \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 20),\n",
    "            \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 20),\n",
    "        }\n",
    "\n",
    "        model = GradientBoostingRegressor(**params, random_state=42)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = model.predict(X_test)\n",
    "        rmse = root_mean_squared_error(y_test, y_pred)\n",
    "        return rmse\n",
    "\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "    return study.best_params, study.best_value"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Попробуем обучить (пока независимо) модели для регрессии двух оставшихся таргетов"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "X_train2, X_test2, y_train2, y_test2 = target_train[['at_least_one']], target_test[['at_least_one']], target_train['at_least_two'], target_test['at_least_two']\n",
    "\n",
    "#params2 = optimize_gradient_boosting(X_train2, X_test2, y_train2, y_test2, 200)[0]\n",
    "\n",
    "model2 = GradientBoostingRegressor()\n",
    "model2.fit(X_train2, y_train2)\n",
    "\n",
    "y_pred2 = model2.predict(X_test2)\n",
    "\n",
    "print_metrics(y_test2, y_pred2)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "X_train3, X_test3, y_train3, y_test3 = target_train[['at_least_two']], target_test[['at_least_two']], target_train['at_least_three'], target_test['at_least_three']\n",
    "\n",
    "#params3 = optimize_gradient_boosting(X_train3, X_test3, y_train3, y_test3, 200)[0]\n",
    "\n",
    "model3 = GradientBoostingRegressor()\n",
    "model3.fit(X_train3, y_train3)\n",
    "\n",
    "y_pred3 = model3.predict(X_test3)\n",
    "\n",
    "print_metrics(y_test3, y_pred3)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "В целом получаются неплохие метрики"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Теперь попробуем объединить модели в одну и посмотрим результат сразу на предложенной метрике"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "from metrics import get_smoothed_mean_log_accuracy_ratio"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "В baseline (все нули) метрика равна"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "baseline = pd.read_csv(os.path.join(data_dir, 'baseline.tsv'), sep='\\t')\n",
    "baseline_train, baseline_test = train_test_split(baseline, test_size=0.33, random_state=42)\n",
    "get_smoothed_mean_log_accuracy_ratio(target_test, baseline_test)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Нам надо сделать лучше)"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "У модели есть параметр, который отвечает за то будет ли каждая \"следующая\" суб-модель обучаться на результатах прошлой модели или будем обучать их независимо"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "class VKAdsRegressor(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, train_independently: bool = False):\n",
    "        self.train_independently = train_independently\n",
    "        self.model1 = CatBoostRegressor(silent=True)\n",
    "        self.model2 = GradientBoostingRegressor()\n",
    "        self.model3 = GradientBoostingRegressor()\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.model1.fit(X, y['at_least_one'])\n",
    "        \n",
    "        if self.train_independently:\n",
    "            self.model2.fit(y[['at_least_one']].to_numpy(), y['at_least_two'])\n",
    "            self.model3.fit(y[['at_least_two']].to_numpy(), y['at_least_three'])\n",
    "        else:\n",
    "            output1 = np.clip(self.model1.predict(X), a_min=0, a_max=1).reshape(-1, 1)\n",
    "            self.model2.fit(output1, y['at_least_two'])\n",
    "\n",
    "            output2 = self.model2.predict(output1).reshape(-1, 1)\n",
    "            self.model3.fit(output2, y['at_least_three'])\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        output1 = np.clip(self.model1.predict(X), a_min=0, a_max=1)\n",
    "        output2 = self.model2.predict(output1.reshape(-1, 1))\n",
    "        output3 = self.model3.predict(output2.reshape(-1, 1))\n",
    "\n",
    "        output = pd.DataFrame()\n",
    "        output['at_least_one'] = output1\n",
    "        output['at_least_two'] = output2\n",
    "        output['at_least_three'] = output3\n",
    "        output = output.set_index(X.index)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Для начала попробуем обучать независимо"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model = VKAdsRegressor(train_independently=True)\n",
    "model.fit(features_train, target_train)\n",
    "\n",
    "target_pred = model.predict(features_test)\n",
    "\n",
    "get_smoothed_mean_log_accuracy_ratio(target_test, target_pred)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "А теперь попробуем во время обучения постараться учесть ошибки модели и каждую следующую суб-модель будем обучать, используя данные предыдущей суб-модели"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model = VKAdsRegressor(train_independently=False)\n",
    "model.fit(features_train, target_train)\n",
    "\n",
    "target_pred = model.predict(features_test)\n",
    "\n",
    "get_smoothed_mean_log_accuracy_ratio(target_test, target_pred)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Немного странно, но получилось так что независимое обучение суб-моделей дало лучший результат, но возможно при оптимизации гиперпараметров модели всё изменится"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "В итоге получили результат ~50 по предложенной метрике, что однозначно лучше чем baseline)"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
